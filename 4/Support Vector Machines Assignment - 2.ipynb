{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6372f9c-7fbe-45c3-887e-2e6b1fd11c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982d720-3a3c-4d4f-b035-ff68b2166f63",
   "metadata": {},
   "source": [
    "Polynomial functions are mathematical functions that involve powers of a variable (e.g., x^2, x^3, etc.). They are used in various machine learning models, such as polynomial regression, to capture non-linear relationships between input features and the target variable.\n",
    "\n",
    "\n",
    "Kernel functions, on the other hand, are used primarily in the context of kernel methods, including SVMs. These methods aim to find a non-linear decision boundary in a higher-dimensional feature space without explicitly calculating the transformed features.\n",
    "\n",
    "\n",
    "Relationship:\n",
    "\n",
    "The relationship between polynomial functions and kernel functions lies in the use of polynomial kernels in SVMs. A polynomial kernel is a type of kernel function that captures polynomial relationships between data points in the feature space.\n",
    "\n",
    "\n",
    "When you use a polynomial kernel in an SVM, you are essentially employing a polynomial function of a specific degree (e.g., degree 2, 3, etc.) to model non-linear decision boundaries in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c3904-af15-44f2-9de8-9f89c18d1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323115d7-b188-47ca-8bfa-87f3fbc50d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import The Necessary Libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load The Iris Dataset \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split The Dataset Into Training And Testing Sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create An SVM Classifier With A Polynomial Kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3, C=1.0)\n",
    "\n",
    "# Train The SVM Classifier On The Training Data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make Predictions On The Test Data \n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate The Classifier's Performance (E.g., Accuracy) \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9d4d5-dc4a-4d5a-8d5a-9ae08acf96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How does increasing the value of epsilon affect the number of support vectors in SVR? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c86277-ba4c-4332-be89-4134500161e3",
   "metadata": {},
   "source": [
    "Increasing the value of epsilon in Support Vector Regression (SVR) typically reduces the number of support vectors. Smaller epsilon values lead to a tighter fit, requiring more support vectors to closely match the data, while larger epsilon values allow for a looser fit with fewer support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f7a4e5-fce5-440a-98da-535630ef2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? \n",
    "\n",
    "# Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb055c-9b50-40e3-9bf1-8962ecad1900",
   "metadata": {},
   "source": [
    "# Choice of Kernel Function:\n",
    "\n",
    "Use a linear kernel for mostly linear data, and non-linear kernels (e.g., RBF) for non-linear data.\n",
    "\n",
    "# C Parameter:\n",
    "\n",
    "Increase C to fit the training data closely.\n",
    "\n",
    "Decrease C to prioritize a larger margin and avoid overfitting.\n",
    "\n",
    "# Epsilon Parameter (ε):\n",
    "\n",
    "Increase ε for more tolerance to errors.\n",
    "Decrease ε for a closer fit to the data with less tolerance for errors.\n",
    "\n",
    "# Gamma Parameter (γ):\n",
    "\n",
    "Increase γ for localized, complex patterns.\n",
    "Decrease γ for smoother, global patterns, especially with noisy data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb4901-5e54-4c37-9cba-183e91cff2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q5. Assignment:\n",
    "#  Import the necessary libraries and load the dataset\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "# Preprocess the data using any technique of your choice (e.g. scaling, normalization) \n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "\n",
    "# Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score) \n",
    "\n",
    "# Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performanc\n",
    "\n",
    "# Train the tuned classifier on the entire dataset \n",
    "\n",
    "# Save the trained classifier to a file for future use.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d932e0-e421-414f-a801-c8f2fb2a360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Classifier Accuracy: 1.0\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import The Necessary Libraries \n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import joblib \n",
    "\n",
    "# Load The Iris Dataset \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split The Dataset Into Training And Testing Sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40) \n",
    "\n",
    "# Preprocess The Data Using Standard Scaler For Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "# Create An Instance Of The SVC Classifier With An Initial Set Of Hyperparameters \n",
    "initial_svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=40) \n",
    "\n",
    "\n",
    "# Train The Initial Classifier On The Training Data \n",
    "initial_svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use The Initial Classifier To Predict The Labels Of The Testing Data \n",
    "y_pred = initial_svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate The Performance Of The Initial Classifier Using Accuracy \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Initial Classifier Accuracy:\", accuracy)\n",
    "\n",
    "# Tune Hyperparameters Using GridSearchCV \n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get The Best Hyperparameters From The Grid Search \n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train The Tuned Classifier On The Entire Dataset \n",
    "final_svm_classifier = SVC(**best_params, random_state=40)\n",
    "final_svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save The Trained Classifier To A File For Future Use \n",
    "joblib.dump(final_svm_classifier, 'svm_classifier.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
